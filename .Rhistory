data_hp_cl$land_size <- round(data_hp_cl$land_size, 2)
unique(data_hp_cl$land_size)
rows_with_3125 <- data_hp_cl[data_hp_cl$land_size == 3125, ]
rows_with_3125
data_hp_cl <- read_excel("data/data-hp-cl.xlsx")
unique(data_hp_cl$land_size)
data_hp_cl$land_size <- round(data_hp_cl$land_size, 2)
data_hp_cl$land_size <- as.numeric(as.character(data_hp_cl$land_size))
data_hp_cl$land_size <- round(data_hp_cl$land_size, 2)
unique(data_hp_cl$land_size)
mean(data_hp_cl$land_size)
mean_value <- mean(data_hp_cl$land_size, na.rm = TRUE)
mean_value
test_data <- scraped_data1 %>% slice(1)
library(tidyverse)
library(readxl)
test_data <- scraped_data1 %>% slice(1)
# Read your data
scraped_data1 <- read_csv("data/houseprice_scraped.csv")
test_data <- scraped_data1 %>% slice(1)
# Run the extraction for just one caption
single_result <- test_data %>%
mutate(
extracted_info = map(caption, extract_info),
kampong = map_chr(extracted_info, ~ .["kampong"]),
price = map_chr(extracted_info, ~ .["price"]),
type = map_chr(extracted_info, ~ .["type"]),
storey = map_chr(extracted_info, ~ .["storey"]),
status = map_chr(extracted_info, ~ .["status"]),
land_size = map_chr(extracted_info, ~ .["land_size"]),
floor_size = map_chr(extracted_info, ~ .["floor_size"]),
beds = map_chr(extracted_info, ~ .["beds"]),
baths = map_chr(extracted_info, ~ .["baths"]),
land_type = map_chr(extracted_info, ~ .["land_type"]),
additional_remark = map_chr(extracted_info, ~ .["Additional Remark"])
)
# Define the extract_info function as before
extract_info <- function(caption) {
# Create command to send caption to ollama for processing
command <- paste('ollama run llama3.1 "Extract the following details from this caption: kampong, price, type, storey, status, land_size, floor_size, beds, baths, land_type, and anything else should go to Additional Remark. Caption: ', caption, '"', sep = "")
# Execute the command in terminal and get the output
result <- system(command, intern = TRUE)
return(result)
}
# Run the extraction for just one caption
single_result <- test_data %>%
mutate(
extracted_info = map(caption, extract_info),
kampong = map_chr(extracted_info, ~ .["kampong"]),
price = map_chr(extracted_info, ~ .["price"]),
type = map_chr(extracted_info, ~ .["type"]),
storey = map_chr(extracted_info, ~ .["storey"]),
status = map_chr(extracted_info, ~ .["status"]),
land_size = map_chr(extracted_info, ~ .["land_size"]),
floor_size = map_chr(extracted_info, ~ .["floor_size"]),
beds = map_chr(extracted_info, ~ .["beds"]),
baths = map_chr(extracted_info, ~ .["baths"]),
land_type = map_chr(extracted_info, ~ .["land_type"]),
additional_remark = map_chr(extracted_info, ~ .["Additional Remark"])
)
library(tidyverse)
# Read the data
scraped_data1 <- read_csv("data/houseprice_scraped.csv")
# Extract the first 10 captions and save them into a CSV
first_10_captions <- scraped_data1 %>%
slice(1:10) %>%
select(caption)
# Save the first 10 captions to a new CSV
write_csv(first_10_captions, "first_10_captions.csv")
test_data <- scraped_data1 %>% slice(1)
# Run the extraction for just one caption
single_result <- test_data %>%
mutate(
extracted_info = map(caption, extract_info),
kampong = map_chr(extracted_info, ~ .["kampong"]),
price = map_chr(extracted_info, ~ .["price"]),
type = map_chr(extracted_info, ~ .["type"]),
storey = map_chr(extracted_info, ~ .["storey"]),
status = map_chr(extracted_info, ~ .["status"]),
land_size = map_chr(extracted_info, ~ .["land_size"]),
floor_size = map_chr(extracted_info, ~ .["floor_size"]),
beds = map_chr(extracted_info, ~ .["beds"]),
baths = map_chr(extracted_info, ~ .["baths"]),
land_type = map_chr(extracted_info, ~ .["land_type"]),
additional_remark = map_chr(extracted_info, ~ .["Additional Remark"])
)
#create a function to process the rest of the captions
process_caption <- function(caption) {
caption_clean <- gsub('"', '', caption)
prompt <- paste0(
"Extract the following details from this:
- kampong: village in Brunei.
- price: Identify the price details.
- type: Identify the words - apartment, bungalow, detached, semi-detached.
- storey: Identify if it is a single storey or a double storey.
- status: Identify whther it is new, proposed, or under-construction.
- land_size: Extract the land size.
- floor_size: Extract the floor size.
- beds: Number of bedrooms.
- baths: Number of bathrooms.
- land_type: Identify if it Leasehold or In perpetuity or Kekal
- Additional Remark: The remaining details.
Caption: '", caption_clean, "'"
)
# Run the Ollama model on the prompt
result <- generate("llama3.1", prompt, output = "text")
return(result)
}
library(ollamar)
library(dplyr)
library(readxl)
library(writexl)
library(writexl)
library(ollamar)
library(dplyr)
library(readxl)
library(writexl)
#testing connection & ensure the model is pulled
test_connection()
pull("llama3.1")
install.packages("ollamar")
library(ollamar)
library(dplyr)
library(readxl)
library(writexl)
#testing connection & ensure the model is pulled
test_connection()
pull("llama3.1")
library(ollamar)
pull("llama3.1")
install.packages("ollamar")
pull("llama3.1")
??ollamar
pull("llama3")
pull("llama3.1")
pull ("llama3.1")
#testing connection & ensure the model is pulled
test_connection()
library(ollamar)
#testing connection & ensure the model is pulled
test_connection()
pull("llama3.1")
install.packages("ollamar")
library(ollamar)
library(dplyr)
library(readxl)
library(writexl)
#testing connection & ensure the model is pulled
test_connection()
pull("llama3.1")
install.packages("ollamar")
library(ollamar)
library(dplyr)
library(readxl)
library(writexl)
#testing connection & ensure the model is pulled
test_connection()
pull("llama3.1")
install.packages("ollamar")
library(ollamar)
#testing connection & ensure the model is pulled
test_connection()
pull("llama3.1")
kpg_mkm_df <- read.csv("/Users/amirabarizah/Documents/data-hp/data/bn_kpg_level_data.csv")
kpg_names <- gsub("^Kg\\.\\s*", "", kpg_mkm_df$kampong)
#converting to a single string for ollama prompt
kampong_list <- paste(kpg_names, collapse = ", ")
#vector of captions
hpsc <- read.csv("/Users/amirabarizah/Documents/data-hp/data/houseprice_scraped.csv")
hpsc_captions <- hpsc$caption
#create a function to process the rest of the captions
process_caption <- function(caption) {
caption_clean <- gsub('"', '', caption)
prompt <- paste0(
"Extract the following details from this:
- kampong: village in Brunei.
- price: Identify the price details.
- type: Identify the words - apartment, bungalow, detached, semi-detached.
- storey: Identify if it is a single storey or a double storey.
- status: Identify whther it is new, proposed, or under-construction.
- land_size: Extract the land size.
- floor_size: Extract the floor size.
- beds: Number of bedrooms.
- baths: Number of bathrooms.
- land_type: Identify if it Leasehold or In perpetuity or Kekal
- Additional Remark: The remaining details.
Caption: '", caption_clean, "'"
)
# Run the Ollama model on the prompt
result <- generate("llama3.1", prompt, output = "text")
return(result)
}
#empty list
results <- list()
#loop
for (i in 1:min(length(hpsc_captions), 50)) {
results[[i]] <- process_caption(hpsc_captions[i])
}
View(results)
results_df <- data.frame(results)
write_xlsx(results_df, "/Users/amirabarizah/Documents/data-hp/data/results_50.csv")
library(writexl)
results_df <- data.frame(results)
write_xlsx(results_df, "/Users/amirabarizah/Documents/data-hp/data/results_50.csv")
View(results)
# Convert the list of results to a dataframe
results_df <- data.frame(result = unlist(results))
write_xlsx(results_df, "/Users/amirabarizah/Documents/data-hp/data/results_50.csv")
# Convert the list of results to a dataframe
results_df <- data.frame(result = unlist(results))
# Save to an Excel file
write_xlsx(results_df, "/path/to/save/results.xlsx")
write_xlsx(results_df, "/Users/amirabarizah/Documents/data-hp/data/results_50.csv")
#create a function to process the rest of the captions
process_caption <- function(caption) {
caption_clean <- gsub('"', '', caption)
prompt <- paste0(
"Extract the following details from this:
- kampong: Identify the kampong (village in Brunei) mentioned.
- price: Identify the price details.
- type: Identify the words - apartment, bungalow, detached, semi-detached.
- storey: Identify if it is a single storey or a double storey.
- status: Identify whther it is new, proposed, or under-construction.
- land_size: Extract the land size.
- floor_size: Extract the floor size.
- beds: Number of bedrooms.
- baths: Number of bathrooms.
- land_type: Identify if it Leasehold or In perpetuity or Kekal
- Additional Remark: The remaining details.
Caption: '", caption_clean, "'"
)
# Run the Ollama model on the prompt
result <- generate("llama3.1", prompt, output = "text")
return(result)
}
#empty list
results <- list()
#loop
for (i in 40:min(length(hpsc_captions), 50)) {
results[[i]] <- process_caption(hpsc_captions[i])
}
# Convert the list of results to a dataframe
results_df <- data.frame(result = unlist(results))
write_xlsx(results_df, "/Users/amirabarizah/Documents/data-hp/data/results_50.csv")
#testing connection & ensure the model is pulled
test_connection()
pull("llama3.1")
#vector of captions
hpsc <- read.csv("/Users/amirabarizah/Documents/data-hp/data/houseprice_scraped.csv")
hpsc_captions <- hpsc$caption
#create a function to process the rest of the captions
process_caption <- function(caption) {
caption_clean <- gsub('"', '', caption)
prompt <- paste0(
"Extract the following details from this:
- kampong: Identify the kampong (village in Brunei) mentioned.
- price: Identify the price details.
- type: Identify the words - apartment, bungalow, detached, semi-detached.
- storey: Identify if it is a single storey or a double storey.
- status: Identify whther it is new, proposed, or under-construction.
- land_size: Extract the land size.
- floor_size: Extract the floor size.
- beds: Number of bedrooms.
- baths: Number of bathrooms.
- land_type: Identify if it Leasehold or In perpetuity or Kekal
- Additional Remark: The remaining details.
Caption: '", caption_clean, "'"
)
# Run the Ollama model on the prompt
result <- generate("llama3.1", prompt, output = "text")
return(result)
}
#empty list
results <- list()
#loop
for (i in 1:min(length(hpsc_captions), 100)) {
results[[i]] <- process_caption(hpsc_captions[i])
}
library(ollamar)
#testing connection & ensure the model is pulled
test_connection()
pull("llama3.1")
results[[i]] <- process_caption(hpsc_captions[i])
View(results)
#loop
for (i in 901:min(length(hpsc_captions), 1000)) {
results[[i]] <- process_caption(hpsc_captions[i])
}
# Convert the list of results to a dataframe
results_df <- data.frame(result = unlist(results))
write.csv(results_df, "/Users/amirabarizah/Documents/data-hp/data/results200.csv")
#loop
for (i in 1001:min(length(hpsc_captions), 1100)) {
results[[i]] <- process_caption(hpsc_captions[i])
}
# Convert the list of results to a dataframe
results_df <- data.frame(result = unlist(results))
write.csv(results_df, "/Users/amirabarizah/Documents/data-hp/data/results200.csv")
write.csv(results_df, "/Users/amirabarizah/Documents/data-hp/data/results.csv")
View(results)
# Convert the list of results to a dataframe
results_df <- data.frame(result = unlist(results))
write.csv(results_df, "/Users/amirabarizah/Documents/data-hp/data/results.csv")
# Function to parse individual data entries
parse_data <- function(text) {
# Clean up text to remove unwanted characters and spaces
text_cleaned <- str_squish(text)
# Extract each component using regex
date <- str_extract(text_cleaned, "(?<=Date: )\\d{4}\\d{2}\\d{2}")
kampong <- str_extract(text_cleaned, "(?<=kampong: )[\\w\\s]+")
price <- str_extract(text_cleaned, "(?<=price: )[^\\n\\s]+")
type <- str_extract(text_cleaned, "(?<=type: )[\\w\\s]+")
storey <- str_extract(text_cleaned, "(?<=storey: )[\\w\\s]+")
status <- str_extract(text_cleaned, "(?<=status: )[\\w\\s]+")
land_size <- str_extract(text_cleaned, "(?<=land_size: )[\\d.]+\\s[\\w]+")
floor_size <- str_extract(text_cleaned, "(?<=floor_size: )[\\d]+\\s[\\w]+")
beds <- str_extract(text_cleaned, "(?<=beds: )[\\d]+\\s[\\w]+")
baths <- str_extract(text_cleaned, "(?<=baths: )[\\d]+\\s[\\w]+")
land_type <- str_extract(text_cleaned, "(?<=land_type: )[\\w\\s]+")
# Extract Additional Remark section
additional_remark_start <- str_locate(text_cleaned, "Additional Remark:")[, "end"]
if (!is.na(additional_remark_start)) {
additional_remark <- substr(text_cleaned, additional_remark_start + 1, nchar(text_cleaned))
additional_remark <- str_squish(additional_remark)  # Remove extra white spaces
} else {
additional_remark <- NA
}
list(
date = date,
kampong = kampong,
price = price,
type = type,
storey = storey,
status = status,
land_size = land_size,
floor_size = floor_size,
beds = beds,
baths = baths,
land_type = land_type,
additional_remark = additional_remark
)
}
# Function to parse all entries from the text data
parse_all_entries <- function(text_data) {
# Initialize lists to store parsed results
dates <- c()
kampongs <- c()
prices <- c()
types <- c()
storeys <- c()
statuses <- c()
land_sizes <- c()
floor_sizes <- c()
beds <- c()
baths <- c()
land_types <- c()
additional_remarks <- c()
# Split the text data into lines
lines <- str_split(text_data, "\n")[[1]]
# Initialize a variable to hold each entry
current_entry <- ""
# Loop through each line to process entries
for (line in lines) {
if (str_detect(line, "\\*\\*\\d+\\. Atlasproperties_bn")) {
if (nchar(current_entry) > 0) {
# Parse the current entry
parsed <- parse_data(current_entry)
# Append the results
dates <- c(dates, parsed$date)
kampongs <- c(kampongs, parsed$kampong)
prices <- c(prices, parsed$price)
types <- c(types, parsed$type)
storeys <- c(storeys, parsed$storey)
statuses <- c(statuses, parsed$status)
land_sizes <- c(land_sizes, parsed$land_size)
floor_sizes <- c(floor_sizes, parsed$floor_size)
beds <- c(beds, parsed$beds)
baths <- c(baths, parsed$baths)
land_types <- c(land_types, parsed$land_type)
additional_remarks <- c(additional_remarks, parsed$additional_remark)
}
# Start a new entry
current_entry <- line
} else {
# Append the line to the current entry
current_entry <- paste0(current_entry, "\n", line)
}
}
# Don't forget to parse the last entry
if (nchar(current_entry) > 0) {
parsed <- parse_data(current_entry)
dates <- c(dates, parsed$date)
kampongs <- c(kampongs, parsed$kampong)
prices <- c(prices, parsed$price)
types <- c(types, parsed$type)
storeys <- c(storeys, parsed$storey)
statuses <- c(statuses, parsed$status)
land_sizes <- c(land_sizes, parsed$land_size)
floor_sizes <- c(floor_sizes, parsed$floor_size)
beds <- c(beds, parsed$beds)
baths <- c(baths, parsed$baths)
land_types <- c(land_types, parsed$land_type)
additional_remarks <- c(additional_remarks, parsed$additional_remark)
}
# Create a tibble from the results
results_df <- tibble(
date = dates,
kampong = kampongs,
price = prices,
type = types,
storey = storeys,
status = statuses,
land_size = land_sizes,
floor_size = floor_sizes,
beds = beds,
baths = baths,
land_type = land_types,
additional_remark = additional_remarks
)
return(results_df)
}
library(readxl)
# Example usage
extracted_data <- read.csv("/Users/amirabarizah/Documents/data-hp/data/results200.csv")
write.csv(results, "/Users/amirabarizah/Documents/data-hp/data/trial_results.csv")
# Convert the list of results to a dataframe
results_df <- data.frame(result = unlist(results))
write.csv(results, "/Users/amirabarizah/Documents/data-hp/data/trial_results.csv")
write.csv(results_df, "/Users/amirabarizah/Documents/data-hp/data/results200.csv")
View(results)
write.csv(results_df, "/Users/amirabarizah/Documents/data-hp/data/trial_results.csv")
View(results)
# Convert the list of results to a dataframe
results_df <- data.frame(results = unlist(results))
# Convert the list of results to a dataframe
results_df <- data.frame(results = unlist(results))
source("~/Documents/data-hp/ollama-cl-1.R", echo=TRUE)
#testing connection & ensure the model is pulled
test_connection()
pull("llama3.1")
#vector of captions
hpsc <- read.csv("/Users/amirabarizah/Documents/data-hp/data/houseprice_scraped.csv")
hpsc_captions <- hpsc$caption
#create a function to process the rest of the captions
process_caption <- function(caption) {
caption_clean <- gsub('"', '', caption)
prompt <- paste0(
"Extract the following details from this:
- kampong: Identify the kampong (village in Brunei) mentioned.
- price: Identify the price details.
- type: Identify the words - apartment, bungalow, detached, semi-detached.
- storey: Identify if it is a single storey or a double storey.
- status: Identify whther it is new, proposed, or under-construction.
- land_size: Extract the land size.
- floor_size: Extract the floor size.
- beds: Number of bedrooms.
- baths: Number of bathrooms.
- land_type: Identify if it Leasehold or In perpetuity or Kekal
- Additional Remark: The remaining details.
Caption: '", caption_clean, "'"
)
# Run the Ollama model on the prompt
result <- generate("llama3.1", prompt, output = "text")
return(result)
}
# Convert the list of results to a dataframe
results_df <- data.frame(results = unlist(results))
str(results)
View(results)
pull("llama3.1")
library(ollamar)
#testing connection & ensure the model is pulled
test_connection()
pull("llama3.1")
# Convert the list of results to a dataframe
results_df <- data.frame(results = unlist(results))
write.csv(results_df, "/Users/amirabarizah/Documents/data-hp/data/results200.csv")
View(results)
#loop
for (i in 900:min(length(hpsc_captions), 903)) {
results[[i]] <- process_caption(hpsc_captions[i])
}
# Convert the list of results to a dataframe
results_df <- data.frame(results = unlist(results))
# Convert the list of results to a dataframe
results_df <- data.frame(results = results)
#loop
for (i in 1101:min(length(hpsc_captions), 1103)) {
results[[i]] <- process_caption(hpsc_captions[i])
}
View(results)
# Convert the list of results to a dataframe
results_df <- data.frame(results = results)
# Convert the list of results to a dataframe
results_df <- data.frame(results = unlist(results))
write.csv(results_df, "/Users/amirabarizah/Documents/data-hp/data/results200.csv")
View(results)
#loop
for (i in 1104:min(length(hpsc_captions), 1204)) {
results[[i]] <- process_caption(hpsc_captions[i])
}
# Convert the list of results to a dataframe
results_df <- data.frame(results = unlist(results))
write.csv(results_df, "/Users/amirabarizah/Documents/data-hp/data/results32_1200.csv")
#loop
for (i in 1205:min(length(hpsc_captions), 1300)) {
results[[i]] <- process_caption(hpsc_captions[i])
}
# Convert the list of results to a dataframe
results_df <- data.frame(results = unlist(results))
write.csv(results_df, "/Users/amirabarizah/Documents/data-hp/data/results32_1200.csv")
View(results)
